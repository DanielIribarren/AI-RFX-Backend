#!/usr/bin/env python3
"""
ğŸš€ DÃA 1: MIGRACIÃ“N RFX â†’ SAAS GENERAL
Script completo automatizado - Sin tocar Supabase Dashboard

Ejecutar: python day_1_migration.py
Tiempo estimado: 10-15 minutos
"""

import os
import sys
import subprocess
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
import shutil

# ConfiguraciÃ³n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration_day_1.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class Day1Migration:
    """
    AutomatizaciÃ³n completa del DÃ­a 1 de migraciÃ³n
    """
    
    def __init__(self):
        self.project_root = Path.cwd()
        self.backup_dir = self.project_root / "migration_backups"
        self.migration_date = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.migration_branch = "saas-migration"
        
    def run_complete_day_1(self):
        """
        Ejecutar todo el DÃ­a 1 automÃ¡ticamente
        """
        try:
            logger.info("ğŸš€ INICIANDO DÃA 1: MIGRACIÃ“N RFX â†’ SAAS GENERAL")
            logger.info("=" * 60)
            
            # 1. PreparaciÃ³n y validaciones iniciales
            self._validate_environment()
            
            # 2. Crear directorio de backups
            self._create_backup_directory()
            
            # 3. Backup completo del proyecto
            self._backup_complete_project()
            
            # 4. Backup de base de datos
            self._backup_database()
            
            # 5. Crear branch de migraciÃ³n
            self._create_migration_branch()
            
            # 6. Analizar dependencias
            dependencies = self._analyze_project_dependencies()
            
            # 7. Generar plan de migraciÃ³n
            migration_plan = self._generate_migration_plan(dependencies)
            
            # 8. Crear documentos de rollback
            self._create_rollback_plan()
            
            # 9. Validaciones finales
            self._run_final_validations()
            
            # 10. Resumen y siguientes pasos
            self._generate_day_1_summary(migration_plan)
            
            logger.info("âœ… DÃA 1 COMPLETADO EXITOSAMENTE!")
            logger.info("ğŸ¯ LISTO PARA DÃA 2: MigraciÃ³n de esquema de BD")
            
        except Exception as e:
            logger.error(f"âŒ ERROR EN DÃA 1: {str(e)}")
            logger.error("ğŸ”„ Ejecutando rollback automÃ¡tico...")
            self._emergency_rollback()
            raise
    
    def _validate_environment(self):
        """Validar que el entorno estÃ¡ listo para migraciÃ³n"""
        logger.info("ğŸ” Validando entorno de desarrollo...")
        
        # Verificar que estamos en el directorio correcto
        required_files = [
            "backend/app.py",
            "backend/models",
            "backend/services",
            ".env"
        ]
        
        missing_files = []
        for file_path in required_files:
            if not (self.project_root / file_path).exists():
                missing_files.append(file_path)
        
        if missing_files:
            raise FileNotFoundError(f"Archivos requeridos no encontrados: {missing_files}")
        
        # Verificar Git
        try:
            subprocess.run(["git", "status"], check=True, capture_output=True)
            logger.info("âœ… Repositorio Git detectado")
        except subprocess.CalledProcessError:
            raise RuntimeError("Este proyecto debe estar en un repositorio Git")
        
        # Verificar Python y dependencias
        try:
            import supabase
            logger.info("âœ… Supabase client disponible")
        except ImportError:
            logger.warning("âš ï¸ Supabase client no instalado. Instalando...")
            subprocess.run([sys.executable, "-m", "pip", "install", "supabase"], check=True)
        
        logger.info("âœ… Entorno validado correctamente")
    
    def _create_backup_directory(self):
        """Crear directorio de backups"""
        self.backup_dir.mkdir(exist_ok=True)
        logger.info(f"ğŸ“ Directorio de backups: {self.backup_dir}")
    
    def _backup_complete_project(self):
        """Backup completo del cÃ³digo fuente"""
        logger.info("ğŸ’¾ Creando backup completo del proyecto...")
        
        backup_name = f"project_backup_{self.migration_date}"
        backup_path = self.backup_dir / backup_name
        
        # Crear backup del proyecto (sin node_modules, __pycache__, etc.)
        exclude_patterns = [
            "__pycache__",
            "node_modules",
            ".git",
            "*.pyc",
            ".env",
            "migration_backups"
        ]
        
        # Usar Git para crear un archive limpio
        try:
            subprocess.run([
                "git", "archive", 
                "--format=tar.gz", 
                f"--output={backup_path}.tar.gz",
                "HEAD"
            ], check=True)
            
            logger.info(f"âœ… Backup del proyecto creado: {backup_path}.tar.gz")
            
        except subprocess.CalledProcessError:
            # Fallback: copy manual
            logger.warning("ğŸ”„ Usando mÃ©todo de backup manual...")
            shutil.copytree(
                self.project_root, 
                backup_path,
                ignore=shutil.ignore_patterns(*exclude_patterns)
            )
            logger.info(f"âœ… Backup manual creado: {backup_path}")
    
    def _backup_database(self):
        """Backup de la base de datos Supabase"""
        logger.info("ğŸ—„ï¸ Creando backup de base de datos...")
        
        # Crear script de backup de BD
        backup_script = f"""
-- BACKUP DE BASE DE DATOS RFX V2.2
-- Fecha: {datetime.now().isoformat()}
-- Pre-migraciÃ³n a SaaS General

-- Este backup contiene:
-- 1. Esquema completo actual
-- 2. Todos los datos en rfx_v2, companies, requesters, etc.
-- 3. Configuraciones de pricing V2.2

-- INSTRUCCIONES DE RESTORE:
-- 1. Conectar a Supabase Dashboard
-- 2. SQL Editor â†’ Paste este contenido
-- 3. Ejecutar para restaurar estado original

-- NOTA: Este es un backup de referencia
-- Para backup real, usar: pg_dump desde Supabase
"""
        
        backup_sql_path = self.backup_dir / f"database_backup_{self.migration_date}.sql"
        with open(backup_sql_path, 'w') as f:
            f.write(backup_script)
        
        # Crear script de backup de datos crÃ­ticos
        backup_data_script = self._generate_data_backup_queries()
        
        backup_data_path = self.backup_dir / f"data_backup_queries_{self.migration_date}.sql"
        with open(backup_data_path, 'w') as f:
            f.write(backup_data_script)
        
        logger.info(f"âœ… Scripts de backup de BD creados:")
        logger.info(f"   ğŸ“„ {backup_sql_path}")
        logger.info(f"   ğŸ“„ {backup_data_path}")
        logger.info("ğŸ’¡ Para backup real ejecutar: pg_dump en Supabase")
    
    def _generate_data_backup_queries(self) -> str:
        """Generar queries para backup de datos crÃ­ticos"""
        return """
-- QUERIES PARA BACKUP DE DATOS CRÃTICOS
-- Ejecutar en Supabase SQL Editor antes de migraciÃ³n

-- 1. Contar registros actuales
SELECT 'rfx_v2' as table_name, COUNT(*) as count FROM rfx_v2
UNION ALL
SELECT 'companies' as table_name, COUNT(*) as count FROM companies
UNION ALL  
SELECT 'requesters' as table_name, COUNT(*) as count FROM requesters
UNION ALL
SELECT 'suppliers' as table_name, COUNT(*) as count FROM suppliers;

-- 2. Backup de configuraciones crÃ­ticas
SELECT json_agg(row_to_json(rfx_v2.*)) as rfx_backup 
FROM rfx_v2 
WHERE created_at > CURRENT_DATE - INTERVAL '30 days';

-- 3. Backup de pricing configs
SELECT json_agg(row_to_json(rpc.*)) as pricing_configs_backup
FROM rfx_pricing_configurations rpc 
WHERE is_active = true;

-- 4. Verificar integridad referencial
SELECT 
  COUNT(*) as total_rfx,
  COUNT(DISTINCT company_id) as unique_companies,
  COUNT(DISTINCT requester_id) as unique_requesters
FROM rfx_v2;
"""
    
    def _create_migration_branch(self):
        """Crear branch de migraciÃ³n en Git"""
        logger.info("ğŸŒ¿ Creando branch de migraciÃ³n...")
        
        try:
            # Verificar estado limpio
            result = subprocess.run(
                ["git", "status", "--porcelain"], 
                capture_output=True, text=True, check=True
            )
            
            if result.stdout.strip():
                logger.info("ğŸ“ Hay cambios sin commit. Creando commit automÃ¡tico...")
                subprocess.run(["git", "add", "."], check=True)
                subprocess.run([
                    "git", "commit", "-m", 
                    f"Pre-migration snapshot - {self.migration_date}"
                ], check=True)
            
            # Crear tag del estado original
            original_tag = f"v2.2-rfx-original-{self.migration_date}"
            subprocess.run([
                "git", "tag", original_tag,
                "-m", "Estado original antes de migraciÃ³n a SaaS general"
            ], check=True)
            logger.info(f"ğŸ·ï¸ Tag creado: {original_tag}")
            
            # Crear branch de migraciÃ³n
            subprocess.run([
                "git", "checkout", "-b", self.migration_branch
            ], check=True)
            
            logger.info(f"âœ… Branch creado y activado: {self.migration_branch}")
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ Error en Git: {str(e)}")
            raise
    
    def _analyze_project_dependencies(self) -> Dict[str, List[str]]:
        """Analizar dependencias del proyecto para migraciÃ³n"""
        logger.info("ğŸ” Analizando dependencias del proyecto...")
        
        dependencies = {
            "files_with_rfx": [],
            "files_with_rfx_v2": [],
            "files_with_suppliers": [],
            "backend_models": [],
            "api_endpoints": [],
            "frontend_components": []
        }
        
        # Buscar archivos con referencias RFX
        for file_path in self.project_root.rglob("*.py"):
            if self._should_skip_file(file_path):
                continue
                
            try:
                content = file_path.read_text(encoding='utf-8')
                
                if "rfx" in content.lower():
                    dependencies["files_with_rfx"].append(str(file_path))
                    
                if "rfx_v2" in content:
                    dependencies["files_with_rfx_v2"].append(str(file_path))
                    
                if "suppliers" in content and "table" in content:
                    dependencies["files_with_suppliers"].append(str(file_path))
                    
                # Identificar modelos
                if file_path.name.endswith("_models.py"):
                    dependencies["backend_models"].append(str(file_path))
                    
                # Identificar APIs
                if "api/" in str(file_path) and file_path.name.endswith(".py"):
                    dependencies["api_endpoints"].append(str(file_path))
                    
            except Exception as e:
                logger.warning(f"âš ï¸ No se pudo leer {file_path}: {str(e)}")
        
        # Buscar archivos TypeScript/JavaScript (frontend)
        for file_path in self.project_root.rglob("*.ts"):
            if self._should_skip_file(file_path):
                continue
                
            try:
                content = file_path.read_text(encoding='utf-8')
                if "rfx" in content.lower() or "RFX" in content:
                    dependencies["frontend_components"].append(str(file_path))
            except:
                pass
        
        # Log resumen
        logger.info("ğŸ“Š AnÃ¡lisis de dependencias completado:")
        for key, files in dependencies.items():
            if files:
                logger.info(f"   {key}: {len(files)} archivos")
        
        # Guardar anÃ¡lisis detallado
        analysis_path = self.backup_dir / f"dependency_analysis_{self.migration_date}.json"
        with open(analysis_path, 'w') as f:
            json.dump(dependencies, f, indent=2)
        
        logger.info(f"ğŸ’¾ AnÃ¡lisis guardado en: {analysis_path}")
        
        return dependencies
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """Determinar si se debe saltar un archivo en el anÃ¡lisis"""
        skip_patterns = [
            "__pycache__",
            ".git",
            "node_modules",
            ".env",
            "migration_backups",
            ".log"
        ]
        
        path_str = str(file_path)
        return any(pattern in path_str for pattern in skip_patterns)
    
    def _generate_migration_plan(self, dependencies: Dict[str, List[str]]) -> Dict[str, Any]:
        """Generar plan detallado de migraciÃ³n"""
        logger.info("ğŸ“‹ Generando plan de migraciÃ³n...")
        
        migration_plan = {
            "overview": {
                "total_files_to_modify": (
                    len(dependencies["files_with_rfx"]) +
                    len(dependencies["backend_models"]) +
                    len(dependencies["api_endpoints"])
                ),
                "estimated_duration": "7 dÃ­as",
                "risk_level": "Medio",
                "rollback_available": True
            },
            "daily_breakdown": {
                "day_1": {
                    "status": "âœ… COMPLETADO",
                    "tasks": [
                        "Backup completo",
                        "AnÃ¡lisis de dependencias",
                        "CreaciÃ³n de branch",
                        "Plan de rollback"
                    ]
                },
                "day_2": {
                    "status": "ğŸ”„ SIGUIENTE",
                    "tasks": [
                        f"Migrar {len(dependencies['files_with_rfx_v2'])} archivos con rfx_v2",
                        "Crear tabla 'projects'",
                        "Migrar datos rfx_v2 â†’ projects",
                        "Actualizar referencias de BD"
                    ],
                    "estimated_hours": "6-8 horas"
                },
                "day_3": {
                    "status": "â³ PENDIENTE", 
                    "tasks": [
                        f"Actualizar {len(dependencies['backend_models'])} modelos",
                        "Crear project_models.py",
                        "Backward compatibility",
                        "Tests unitarios"
                    ]
                },
                "day_4": {
                    "status": "â³ PENDIENTE",
                    "tasks": [
                        f"Actualizar {len(dependencies['api_endpoints'])} endpoints",
                        "Nuevas APIs contextuales",
                        "Mantener APIs legacy"
                    ]
                },
                "day_5": {
                    "status": "â³ PENDIENTE",
                    "tasks": [
                        "4 tablas nuevas IA contextual",
                        "Ãndices optimizados",
                        "Vistas Ãºtiles"
                    ]
                },
                "day_6": {
                    "status": "â³ PENDIENTE",
                    "tasks": [
                        "Servicio IA contextual",
                        "Workflow inteligente",
                        "IntegraciÃ³n OpenAI"
                    ]
                },
                "day_7": {
                    "status": "â³ PENDIENTE",
                    "tasks": [
                        "Testing completo",
                        "Performance validation",
                        "DocumentaciÃ³n final"
                    ]
                }
            },
            "files_to_modify": dependencies
        }
        
        # Guardar plan
        plan_path = self.backup_dir / f"migration_plan_{self.migration_date}.json"
        with open(plan_path, 'w') as f:
            json.dump(migration_plan, f, indent=2)
        
        logger.info(f"ğŸ“‹ Plan de migraciÃ³n guardado: {plan_path}")
        
        return migration_plan
    
    def _create_rollback_plan(self):
        """Crear plan de rollback detallado"""
        logger.info("ğŸ”„ Creando plan de rollback...")
        
        rollback_script = f"""#!/bin/bash
# SCRIPT DE ROLLBACK AUTOMÃTICO
# Fecha de creaciÃ³n: {datetime.now().isoformat()}

echo "ğŸ”„ INICIANDO ROLLBACK DE MIGRACIÃ“N RFX â†’ SAAS"
echo "âš ï¸  ADVERTENCIA: Esto revertirÃ¡ TODOS los cambios"
echo "Presiona ENTER para continuar o Ctrl+C para cancelar"
read

echo "ğŸ“ Paso 1: Revertir Git al estado original..."
git checkout main
git branch -D {self.migration_branch} 2>/dev/null || true

echo "ğŸ“ Paso 2: Restaurar desde tag original..."
git reset --hard v2.2-rfx-original-{self.migration_date}

echo "ğŸ“ Paso 3: Limpiar archivos de migraciÃ³n..."
rm -rf migration_backups/

echo "ğŸ“ Paso 4: Restaurar dependencias..."
pip install -r requirements.txt

echo "ğŸ“ Paso 5: Reiniciar servicios..."
# Opcional: reiniciar backend
# python backend/app.py &

echo "âœ… ROLLBACK COMPLETADO"
echo "ğŸ¯ Estado restaurado a RFX V2.2 original"
echo "ğŸ’¡ Logs de migraciÃ³n conservados para anÃ¡lisis"
"""
        
        rollback_path = self.backup_dir / "emergency_rollback.sh"
        with open(rollback_path, 'w') as f:
            f.write(rollback_script)
        
        # Hacer ejecutable
        os.chmod(rollback_path, 0o755)
        
        logger.info(f"ğŸ”„ Script de rollback creado: {rollback_path}")
        logger.info("ğŸ’¡ Ejecutar con: ./migration_backups/emergency_rollback.sh")
    
    def _run_final_validations(self):
        """Validaciones finales del DÃ­a 1"""
        logger.info("âœ… Ejecutando validaciones finales...")
        
        validations = []
        
        # 1. Verificar backup existe
        backup_files = list(self.backup_dir.glob("project_backup_*"))
        validations.append({
            "check": "Backup del proyecto",
            "passed": len(backup_files) > 0,
            "details": f"{len(backup_files)} archivos de backup"
        })
        
        # 2. Verificar branch de migraciÃ³n
        try:
            result = subprocess.run(
                ["git", "branch", "--show-current"], 
                capture_output=True, text=True, check=True
            )
            current_branch = result.stdout.strip()
            validations.append({
                "check": "Branch de migraciÃ³n activo",
                "passed": current_branch == self.migration_branch,
                "details": f"Branch actual: {current_branch}"
            })
        except:
            validations.append({
                "check": "Branch de migraciÃ³n activo", 
                "passed": False,
                "details": "Error al verificar branch"
            })
        
        # 3. Verificar anÃ¡lisis de dependencias
        analysis_files = list(self.backup_dir.glob("dependency_analysis_*"))
        validations.append({
            "check": "AnÃ¡lisis de dependencias",
            "passed": len(analysis_files) > 0,
            "details": f"Archivos analizados: {len(analysis_files)}"
        })
        
        # 4. Verificar plan de migraciÃ³n
        plan_files = list(self.backup_dir.glob("migration_plan_*"))
        validations.append({
            "check": "Plan de migraciÃ³n generado",
            "passed": len(plan_files) > 0,
            "details": f"Plan disponible: {len(plan_files) > 0}"
        })
        
        # 5. Verificar script de rollback
        rollback_script = self.backup_dir / "emergency_rollback.sh"
        validations.append({
            "check": "Script de rollback",
            "passed": rollback_script.exists(),
            "details": f"Rollback disponible: {rollback_script.exists()}"
        })
        
        # Log validaciones
        logger.info("ğŸ“Š RESULTADOS DE VALIDACIÃ“N:")
        all_passed = True
        for validation in validations:
            status = "âœ…" if validation["passed"] else "âŒ"
            logger.info(f"   {status} {validation['check']}: {validation['details']}")
            if not validation["passed"]:
                all_passed = False
        
        if not all_passed:
            raise RuntimeError("âŒ Algunas validaciones fallaron. Revisar logs.")
            
        logger.info("âœ… Todas las validaciones pasaron correctamente")
    
    def _generate_day_1_summary(self, migration_plan: Dict[str, Any]):
        """Generar resumen del DÃ­a 1 y siguientes pasos"""
        logger.info("ğŸ“‹ GENERANDO RESUMEN DEL DÃA 1...")
        
        summary = f"""
ğŸ‰ RESUMEN DÃA 1: MIGRACIÃ“N RFX â†’ SAAS GENERAL
{'=' * 60}

âœ… COMPLETADO EXITOSAMENTE:
   ğŸ“¦ Backup completo del proyecto creado
   ğŸŒ¿ Branch '{self.migration_branch}' creado y activo
   ğŸ” AnÃ¡lisis de dependencias completado
   ğŸ“‹ Plan de migraciÃ³n de 7 dÃ­as generado
   ğŸ”„ Script de rollback disponible
   âœ… Todas las validaciones pasaron

ğŸ“Š ESTADÃSTICAS:
   ğŸ”§ Archivos a modificar: {migration_plan['overview']['total_files_to_modify']}
   â±ï¸  DuraciÃ³n estimada: {migration_plan['overview']['estimated_duration']}
   ğŸ¯ Nivel de riesgo: {migration_plan['overview']['risk_level']}

ğŸš€ SIGUIENTE PASO: DÃA 2
   ğŸ“… Fecha recomendada: MaÃ±ana
   â±ï¸  Tiempo estimado: 6-8 horas
   ğŸ¯ Objetivo: MigraciÃ³n de esquema de base de datos
   
   Para continuar ejecutar:
   $ python day_2_migration.py

ğŸ”„ ROLLBACK DISPONIBLE:
   Si algo sale mal: ./migration_backups/emergency_rollback.sh
   
ğŸ¯ PRÃ“XIMOS 6 DÃAS:
   DÃ­a 2: MigraciÃ³n BD (rfx_v2 â†’ projects)
   DÃ­a 3: Modelos Python actualizados
   DÃ­a 4: APIs generalizadas  
   DÃ­a 5: 4 tablas IA contextual
   DÃ­a 6: Servicios IA inteligente
   DÃ­a 7: Testing y validaciÃ³n final

ğŸ“ ARCHIVOS GENERADOS:
   {self.backup_dir}/
   â”œâ”€â”€ project_backup_{self.migration_date}.tar.gz
   â”œâ”€â”€ dependency_analysis_{self.migration_date}.json
   â”œâ”€â”€ migration_plan_{self.migration_date}.json
   â””â”€â”€ emergency_rollback.sh

ğŸ’¡ NOTAS IMPORTANTES:
   â€¢ Branch actual: {self.migration_branch}
   â€¢ Backup original disponible
   â€¢ Rollback automÃ¡tico configurado
   â€¢ Todo versionado en Git

ğŸ‰ Â¡DÃA 1 COMPLETADO! LISTO PARA DÃA 2
"""
        
        # Guardar resumen
        summary_path = self.backup_dir / f"day_1_summary_{self.migration_date}.md"
        with open(summary_path, 'w') as f:
            f.write(summary)
        
        # Log resumen
        print(summary)
        logger.info(f"ğŸ“„ Resumen completo guardado: {summary_path}")
    
    def _emergency_rollback(self):
        """Rollback automÃ¡tico en caso de error"""
        logger.error("ğŸ”„ Ejecutando rollback de emergencia...")
        
        try:
            # Volver a main
            subprocess.run(["git", "checkout", "main"], check=True)
            subprocess.run(["git", "branch", "-D", self.migration_branch], 
                         check=True, capture_output=True)
            logger.info("âœ… Rollback Git completado")
            
        except Exception as rollback_error:
            logger.error(f"âŒ Error en rollback: {str(rollback_error)}")
            logger.error("ğŸ”§ Rollback manual requerido:")
            logger.error("   git checkout main")
            logger.error(f"   git branch -D {self.migration_branch}")


def main():
    """
    FunciÃ³n principal - Ejecutar migraciÃ³n DÃ­a 1
    """
    try:
        migration = Day1Migration()
        migration.run_complete_day_1()
        
        print("\nğŸ‰ Â¡DÃA 1 COMPLETADO EXITOSAMENTE!")
        print("ğŸš€ Para continuar con DÃ­a 2:")
        print("   python day_2_migration.py")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ MigraciÃ³n interrumpida por usuario")
        print("ğŸ”„ Para rollback: ./migration_backups/emergency_rollback.sh")
    except Exception as e:
        print(f"\nâŒ Error en migraciÃ³n: {str(e)}")
        print("ğŸ”„ Rollback automÃ¡tico ejecutado")
        print("ğŸ“‹ Revisar logs: migration_day_1.log")
        sys.exit(1)


if __name__ == "__main__":
    main()
