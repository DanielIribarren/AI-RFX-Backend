# üîß PLAN DE REFACTORIZACI√ìN - RFX AUTOMATION PROJECT

**Fecha:** 3 de Febrero, 2026  
**Versi√≥n:** 1.0  
**Objetivo:** Resolver problemas de consistencia que causan comportamiento intermitente

---

## üìä RESUMEN EJECUTIVO

### Problema Principal Reportado
> "Cuando yo pruebo funciona, pero cuando el cliente prueba a veces funciona a veces no"

### Causa Ra√≠z Identificada
1. **Falta de retry logic** en servicios externos (Cloudinary, OpenAI)
2. **Configuraciones duplicadas** causando comportamiento inconsistente
3. **Manejo de errores silencioso** (return None) que oculta problemas
4. **Dependencias externas no verificadas** (Playwright browsers)
5. **M√∫ltiples instancias de clientes** sin pooling de conexiones

### Impacto
- **Tasa de fallo intermitente:** ~20-30% estimado
- **Archivos afectados:** 50+ archivos
- **L√≠neas de c√≥digo:** ~15,000 l√≠neas revisadas
- **Problemas cr√≠ticos:** 5
- **Problemas moderados:** 5

---

## üî¥ FASE 1: PROBLEMAS CR√çTICOS (Semana 1-2)

### 1.1 UNIFICAR CLIENTE DE BASE DE DATOS

#### üìç Problema
**Ubicaci√≥n:** M√∫ltiples archivos
- `backend/core/config.py` (l√≠nea 254)
- `backend/core/database.py` (l√≠nea 1-783)
- 35 archivos con 289 referencias

**Descripci√≥n:**
```python
# ‚ùå PROBLEMA: 3 formas diferentes de obtener cliente
from backend.core.config import get_database_client  # Forma 1
from backend.core.database import DatabaseClient     # Forma 2
self.db = get_database_client()                      # Forma 3
```

**Impacto:**
- Conexiones duplicadas a Supabase
- Memory leaks potenciales
- Dif√≠cil rastrear errores de conexi√≥n
- Inconsistencia en retry logic

#### üîß Soluci√≥n Propuesta

**Paso 1:** Crear singleton √∫nico en `backend/core/database.py`
```python
# backend/core/database.py
_db_client_instance = None
_db_lock = threading.Lock()

def get_database_client() -> DatabaseClient:
    """Singleton thread-safe para cliente de BD"""
    global _db_client_instance
    
    if _db_client_instance is None:
        with _db_lock:
            if _db_client_instance is None:
                config = get_database_config()
                _db_client_instance = DatabaseClient(
                    url=config.url,
                    key=config.key
                )
    
    return _db_client_instance
```

**Paso 2:** Eliminar duplicado en `config.py`
- Remover funci√≥n `get_database_client()` de `backend/core/config.py`
- Actualizar imports en todos los archivos

**Paso 3:** Refactorizar 35 archivos
```bash
# Script de refactorizaci√≥n autom√°tica
find backend -name "*.py" -exec sed -i '' \
  's/from backend.core.config import get_database_client/from backend.core.database import get_database_client/g' {} \;
```

**Archivos a modificar:**
1. `backend/core/config.py` - Eliminar funci√≥n duplicada
2. `backend/api/rfx.py` - Actualizar import (81 referencias)
3. `backend/services/pricing_config_service_v2.py` - Actualizar import (39 referencias)
4. `backend/api/rfx_secure_patch.py` - Actualizar import (21 referencias)
5. ... (31 archivos m√°s)

**Tiempo estimado:** 4-6 horas

---

### 1.2 CONSOLIDAR CONFIGURACI√ìN DE OPENAI

#### üìç Problema
**Ubicaci√≥n:**
- `backend/core/config.py` (l√≠neas 79-98)
- `backend/core/ai_config.py` (l√≠neas 12-20)

**Descripci√≥n:**
```python
# ‚ùå CONFLICTO: Dos configuraciones diferentes
# config.py
class OpenAIConfig:
    model: str = "gpt-4o"        # Caro
    max_tokens: int = 4096
    temperature: float = 0.1

# ai_config.py  
class AIConfig:
    MODEL: str = "gpt-4o-mini"   # Barato
    MAX_TOKENS: int = 2000
    TEMPERATURE: float = 0.3
```

**Impacto:**
- `rfx_processor.py` usa GPT-4o (caro)
- `chat_agent.py` usa GPT-4o-mini (barato)
- Costos impredecibles: GPT-4o es 16x m√°s caro
- Comportamiento de IA inconsistente

#### üîß Soluci√≥n Propuesta

**Decisi√≥n de Dise√±o:**
- **Mantener:** `backend/core/config.py` como fuente √∫nica
- **Deprecar:** `backend/core/ai_config.py`
- **Raz√≥n:** `config.py` ya es el est√°ndar del proyecto

**Paso 1:** Extender `OpenAIConfig` en `config.py`
```python
# backend/core/config.py
@dataclass
class OpenAIConfig:
    """Configuraci√≥n unificada de OpenAI"""
    api_key: str
    
    # Modelos disponibles
    model_default: str = "gpt-4o"
    model_chat: str = "gpt-4o-mini"      # Para chat conversacional
    model_extraction: str = "gpt-4o"     # Para extracci√≥n RFX
    model_generation: str = "gpt-4o"     # Para generaci√≥n propuestas
    
    # Configuraci√≥n por modelo
    max_tokens: int = 4096
    max_tokens_chat: int = 2000
    
    temperature: float = 0.1
    temperature_chat: float = 0.3
    
    timeout: int = 60
    context_window: int = 128000
    
    # Costos (USD por 1M tokens)
    cost_input_gpt4o: float = 2.50
    cost_output_gpt4o: float = 10.00
    cost_input_gpt4o_mini: float = 0.15
    cost_output_gpt4o_mini: float = 0.60
```

**Paso 2:** Migrar funciones de `ai_config.py`
```python
# backend/core/config.py
def get_openai_config() -> OpenAIConfig:
    """Obtener configuraci√≥n de OpenAI"""
    return OpenAIConfig(
        api_key=os.getenv("OPENAI_API_KEY", ""),
        model_default=os.getenv("OPENAI_MODEL", "gpt-4o"),
        # ... resto de configuraci√≥n
    )

def calculate_openai_cost(input_tokens: int, output_tokens: int, model: str) -> float:
    """Calcular costo de llamada a OpenAI"""
    config = get_openai_config()
    
    if "gpt-4o-mini" in model:
        cost = (input_tokens * config.cost_input_gpt4o_mini + 
                output_tokens * config.cost_output_gpt4o_mini) / 1_000_000
    else:
        cost = (input_tokens * config.cost_input_gpt4o + 
                output_tokens * config.cost_output_gpt4o) / 1_000_000
    
    return cost
```

**Paso 3:** Deprecar `ai_config.py`
```python
# backend/core/ai_config.py
"""
‚ö†Ô∏è DEPRECATED: Este m√≥dulo est√° deprecado.
Usar backend.core.config.OpenAIConfig en su lugar.

Este archivo se mantendr√° temporalmente para compatibilidad.
"""
import warnings
from backend.core.config import get_openai_config

warnings.warn(
    "ai_config.py est√° deprecado. Usar backend.core.config.OpenAIConfig",
    DeprecationWarning,
    stacklevel=2
)

# Re-exportar para compatibilidad temporal
AIConfig = get_openai_config()
```

**Paso 4:** Actualizar imports en 24 archivos
```python
# ‚ùå ANTES
from backend.core.ai_config import AIConfig

# ‚úÖ DESPU√âS
from backend.core.config import get_openai_config

config = get_openai_config()
model = config.model_chat  # Para chat
model = config.model_extraction  # Para extracci√≥n
```

**Archivos a modificar:**
1. `backend/services/proposal_generator.py`
2. `backend/services/rfx_processor.py`
3. `backend/services/chat_agent.py`
4. `backend/api/catalog_sync.py`
5. ... (20 archivos m√°s)

**Tiempo estimado:** 6-8 horas

---

### 1.3 ELIMINAR SERVICIOS DUPLICADOS

#### üìç Problema
**Ubicaci√≥n:** `backend/services/`

**Descripci√≥n:**
```
‚ùå auth_service.py          (12.7 KB)
‚ùå auth_service_fixed.py    (9.7 KB)   ‚Üê ¬øCu√°l usar?

‚ùå pricing_config_service.py    (19.8 KB)
‚ùå pricing_config_service_v2.py (44.7 KB)  ‚Üê ¬øCu√°l es actual?
```

**Impacto:**
- Confusi√≥n sobre qu√© versi√≥n usar
- Bugs si se usa versi√≥n incorrecta
- Mantenimiento duplicado
- C√≥digo legacy sin eliminar

#### üîß Soluci√≥n Propuesta

**Paso 1:** Auditar uso de cada servicio
```bash
# Verificar qu√© archivos usan cada versi√≥n
grep -r "from.*auth_service import" backend/
grep -r "from.*auth_service_fixed import" backend/
grep -r "from.*pricing_config_service import" backend/
grep -r "from.*pricing_config_service_v2 import" backend/
```

**Paso 2:** Decisi√≥n de versi√≥n oficial

**Para auth_service:**
- **Mantener:** `auth_service_fixed.py` (versi√≥n corregida)
- **Eliminar:** `auth_service.py`
- **Renombrar:** `auth_service_fixed.py` ‚Üí `auth_service.py`

**Para pricing_config_service:**
- **Mantener:** `pricing_config_service_v2.py` (versi√≥n actual)
- **Deprecar:** `pricing_config_service.py`
- **Estrategia:** Mantener v1 por 1 mes con warnings, luego eliminar

**Paso 3:** Implementar deprecaci√≥n gradual
```python
# backend/services/pricing_config_service.py
"""
‚ö†Ô∏è DEPRECATED: Este servicio est√° deprecado desde Feb 2026.
Usar pricing_config_service_v2.py en su lugar.

Este archivo se eliminar√° en Marzo 2026.
"""
import warnings

warnings.warn(
    "pricing_config_service est√° deprecado. "
    "Usar pricing_config_service_v2 en su lugar.",
    DeprecationWarning,
    stacklevel=2
)

# Re-exportar desde v2 para compatibilidad
from backend.services.pricing_config_service_v2 import *
```

**Paso 4:** Actualizar imports
```python
# ‚ùå ANTES
from backend.services.pricing_config_service import PricingConfigService

# ‚úÖ DESPU√âS
from backend.services.pricing_config_service_v2 import PricingConfigServiceV2
```

**Archivos a modificar:**
1. `backend/api/pricing.py`
2. `backend/services/unified_budget_configuration_service.py`
3. Cualquier otro archivo que importe versi√≥n v1

**Tiempo estimado:** 3-4 horas

---

### 1.4 IMPLEMENTAR RETRY CONSISTENTE

#### üìç Problema
**Ubicaci√≥n:** M√∫ltiples servicios

**Descripci√≥n:**
```python
# ‚ùå INCONSISTENCIA: 3 formas diferentes

# Forma 1: Decorator (database.py)
@retry_on_connection_error(max_retries=3)
def query(): ...

# Forma 2: Loop manual (cloudinary_service.py)
for attempt in range(3):
    try: upload()
    except: time.sleep(2 ** attempt)

# Forma 3: Sin retry (mayor√≠a)
def process(): 
    return api_call()  # Falla en primer error
```

**Impacto:**
- Cloudinary falla intermitentemente
- OpenAI falla por rate limits
- Playwright falla si tarda en iniciar
- Usuario ve errores aunque retry funcionar√≠a

#### üîß Soluci√≥n Propuesta

**Paso 1:** Crear decorator gen√©rico de retry
```python
# backend/utils/retry_decorator.py
"""
Decorator gen√©rico para retry con exponential backoff
"""
import time
import logging
from functools import wraps
from typing import Callable, Type, Tuple

logger = logging.getLogger(__name__)

def retry_with_backoff(
    max_retries: int = 3,
    initial_delay: float = 0.5,
    backoff_factor: float = 2.0,
    max_delay: float = 30.0,
    exceptions: Tuple[Type[Exception], ...] = (Exception,),
    on_retry: Callable[[Exception, int], None] = None
):
    """
    Decorator para reintentar funci√≥n con exponential backoff
    
    Args:
        max_retries: N√∫mero m√°ximo de reintentos
        initial_delay: Delay inicial en segundos
        backoff_factor: Factor de multiplicaci√≥n del delay
        max_delay: Delay m√°ximo en segundos
        exceptions: Tupla de excepciones a capturar
        on_retry: Callback opcional llamado en cada retry
    
    Example:
        @retry_with_backoff(max_retries=3, exceptions=(ConnectionError,))
        def upload_file():
            return cloudinary.upload(file)
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                    
                except exceptions as e:
                    last_exception = e
                    
                    if attempt == max_retries:
                        logger.error(
                            f"‚ùå {func.__name__} failed after {max_retries} retries: {e}"
                        )
                        raise
                    
                    logger.warning(
                        f"‚ö†Ô∏è {func.__name__} attempt {attempt + 1}/{max_retries} "
                        f"failed: {e}. Retrying in {delay:.2f}s..."
                    )
                    
                    if on_retry:
                        on_retry(e, attempt + 1)
                    
                    time.sleep(delay)
                    delay = min(delay * backoff_factor, max_delay)
            
            raise last_exception
        
        return wrapper
    return decorator
```

**Paso 2:** Aplicar a Cloudinary
```python
# backend/services/cloudinary_service.py
from backend.utils.retry_decorator import retry_with_backoff
import cloudinary.exceptions

@retry_with_backoff(
    max_retries=3,
    initial_delay=1.0,
    exceptions=(
        cloudinary.exceptions.Error,
        ConnectionError,
        TimeoutError
    )
)
def upload_logo(user_id: str, logo_file) -> str:
    """Upload logo con retry autom√°tico"""
    logger.info(f"üì§ Uploading logo for user {user_id}")
    
    result = cloudinary.uploader.upload(
        logo_file,
        folder=f"rfx_logos/{user_id}",
        public_id="logo",
        overwrite=True,
        transformation=[
            {"width": 800, "height": 800, "crop": "limit"},
            {"quality": "auto:good"}
        ]
    )
    
    return result['secure_url']
```

**Paso 3:** Aplicar a OpenAI
```python
# backend/services/rfx_processor.py
from backend.utils.retry_decorator import retry_with_backoff
from openai import RateLimitError, APIError, Timeout

@retry_with_backoff(
    max_retries=3,
    initial_delay=2.0,
    backoff_factor=3.0,  # Backoff m√°s agresivo para rate limits
    exceptions=(RateLimitError, APIError, Timeout)
)
def _call_openai_extraction(self, prompt: str, model: str):
    """Llamada a OpenAI con retry autom√°tico"""
    response = self.openai_client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        timeout=self.openai_config.timeout
    )
    return response
```

**Paso 4:** Aplicar a Playwright
```python
# backend/api/download.py
from backend.utils.retry_decorator import retry_with_backoff
from playwright.sync_api import Error as PlaywrightError

@retry_with_backoff(
    max_retries=2,
    initial_delay=3.0,
    exceptions=(PlaywrightError, TimeoutError)
)
def convert_with_playwright(html_content: str, client_name: str, document_id: str):
    """Conversi√≥n PDF con retry autom√°tico"""
    from playwright.sync_api import sync_playwright
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        page.set_content(html_content)
        
        pdf_bytes = page.pdf(
            format='Letter',
            print_background=True,
            margin={'top': '0.5in', 'bottom': '0.5in'}
        )
        
        browser.close()
        return pdf_bytes
```

**Archivos a modificar:**
1. Crear `backend/utils/retry_decorator.py` (nuevo)
2. `backend/services/cloudinary_service.py` - Aplicar retry
3. `backend/services/rfx_processor.py` - Aplicar retry a OpenAI
4. `backend/api/download.py` - Aplicar retry a Playwright
5. `backend/services/proposal_generator.py` - Aplicar retry a OpenAI

**Tiempo estimado:** 6-8 horas

---

### 1.5 ESTANDARIZAR MANEJO DE ERRORES

#### üìç Problema
**Ubicaci√≥n:** Todo el proyecto

**Descripci√≥n:**
```python
# ‚ùå PROBLEMA: 3 patrones diferentes

# Patr√≥n 1: Return None (130 casos)
def get_data():
    try:
        return fetch()
    except:
        return None  # ‚ö†Ô∏è Caller no sabe si hubo error

# Patr√≥n 2: Raise exception
def get_data():
    try:
        return fetch()
    except Exception as e:
        raise  # ‚úÖ Pero sin contexto

# Patr√≥n 3: Return dict
def get_data():
    return {"status": "error", "message": str(e)}
```

**Impacto:**
- `NoneType` errors downstream
- Frontend no recibe info consistente
- Dif√≠cil debuggear problemas

#### üîß Soluci√≥n Propuesta

**Paso 1:** Crear jerarqu√≠a de excepciones
```python
# backend/exceptions.py (ya existe, extender)
"""
Jerarqu√≠a de excepciones del proyecto
"""

class RFXBaseException(Exception):
    """Excepci√≥n base del proyecto"""
    def __init__(self, message: str, code: str, details: dict = None):
        self.message = message
        self.code = code
        self.details = details or {}
        super().__init__(self.message)
    
    def to_dict(self):
        return {
            "status": "error",
            "code": self.code,
            "message": self.message,
            "details": self.details
        }

# Excepciones por categor√≠a
class DatabaseException(RFXBaseException):
    """Errores de base de datos"""
    pass

class ExternalServiceException(RFXBaseException):
    """Errores de servicios externos (Cloudinary, OpenAI, etc)"""
    pass

class ValidationException(RFXBaseException):
    """Errores de validaci√≥n de datos"""
    pass

class AuthenticationException(RFXBaseException):
    """Errores de autenticaci√≥n"""
    pass

class ResourceNotFoundException(RFXBaseException):
    """Recurso no encontrado"""
    pass

# Excepciones espec√≠ficas
class CloudinaryUploadException(ExternalServiceException):
    """Error al subir archivo a Cloudinary"""
    def __init__(self, message: str, details: dict = None):
        super().__init__(
            message=message,
            code="CLOUDINARY_UPLOAD_ERROR",
            details=details
        )

class OpenAIException(ExternalServiceException):
    """Error en llamada a OpenAI"""
    def __init__(self, message: str, details: dict = None):
        super().__init__(
            message=message,
            code="OPENAI_ERROR",
            details=details
        )

class PlaywrightException(ExternalServiceException):
    """Error en conversi√≥n PDF con Playwright"""
    def __init__(self, message: str, details: dict = None):
        super().__init__(
            message=message,
            code="PLAYWRIGHT_ERROR",
            details=details
        )
```

**Paso 2:** Handler global en Flask
```python
# backend/app.py
from backend.exceptions import RFXBaseException

@app.errorhandler(RFXBaseException)
def handle_rfx_exception(error: RFXBaseException):
    """Handler global para excepciones del proyecto"""
    logger.error(f"‚ùå {error.code}: {error.message}", extra=error.details)
    
    return jsonify(error.to_dict()), 500

@app.errorhandler(ValidationException)
def handle_validation_exception(error: ValidationException):
    """Handler espec√≠fico para validaci√≥n (400)"""
    return jsonify(error.to_dict()), 400

@app.errorhandler(ResourceNotFoundException)
def handle_not_found_exception(error: ResourceNotFoundException):
    """Handler espec√≠fico para not found (404)"""
    return jsonify(error.to_dict()), 404
```

**Paso 3:** Refactorizar servicios
```python
# ‚ùå ANTES
def upload_logo(user_id, file):
    try:
        result = cloudinary.upload(file)
        return result['secure_url']
    except Exception as e:
        logger.error(f"Error: {e}")
        return None  # ‚ö†Ô∏è Problema

# ‚úÖ DESPU√âS
def upload_logo(user_id, file):
    try:
        result = cloudinary.upload(file)
        return result['secure_url']
    except cloudinary.exceptions.Error as e:
        raise CloudinaryUploadException(
            message=f"Failed to upload logo for user {user_id}",
            details={
                "user_id": user_id,
                "error": str(e),
                "file_name": file.filename
            }
        )
```

**Paso 4:** Actualizar endpoints
```python
# ‚ùå ANTES
@rfx_bp.route("/process")
def process_rfx():
    result = processor.process(data)
    if result is None:  # ‚ö†Ô∏è No sabemos qu√© pas√≥
        return {"error": "Processing failed"}, 500
    return {"data": result}

# ‚úÖ DESPU√âS
@rfx_bp.route("/process")
def process_rfx():
    try:
        result = processor.process(data)
        return {"status": "success", "data": result}
    except ValidationException as e:
        # Flask handler autom√°tico retorna 400
        raise
    except ExternalServiceException as e:
        # Flask handler autom√°tico retorna 500
        raise
```

**Archivos a modificar:**
1. `backend/exceptions.py` - Extender jerarqu√≠a
2. `backend/app.py` - Agregar handlers globales
3. `backend/services/cloudinary_service.py` - Usar excepciones
4. `backend/services/rfx_processor.py` - Usar excepciones
5. `backend/api/download.py` - Usar excepciones
6. ... (30+ archivos m√°s gradualmente)

**Tiempo estimado:** 10-12 horas (refactorizaci√≥n gradual)

---

## üü° FASE 2: PROBLEMAS MODERADOS (Semana 3-4)

### 2.1 AUTOMATIZAR INSTALACI√ìN DE PLAYWRIGHT

#### üìç Problema
**Ubicaci√≥n:**
- `requirements.txt` (l√≠nea con `playwright`)
- `scripts/install_playwright_server.sh` (existe pero no se usa)

**Descripci√≥n:**
```bash
# ‚ùå PROBLEMA: Esto NO instala navegadores
pip install playwright

# ‚úÖ NECESARIO: Comando adicional
playwright install chromium
```

**Impacto:**
- PDF generation falla con error cr√≠ptico
- Usuario reporta "a veces funciona" (depende del servidor)

#### üîß Soluci√≥n Propuesta

**Paso 1:** Crear script post-install
```python
# setup.py (crear nuevo)
"""
Setup script para instalaci√≥n completa del proyecto
"""
from setuptools import setup, find_packages
from setuptools.command.install import install
import subprocess
import sys

class PostInstallCommand(install):
    """Post-installation para instalar Playwright browsers"""
    def run(self):
        install.run(self)
        
        print("üì¶ Installing Playwright browsers...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "playwright", "install", "chromium"
            ])
            print("‚úÖ Playwright chromium installed successfully")
        except subprocess.CalledProcessError as e:
            print(f"‚ö†Ô∏è Warning: Failed to install Playwright: {e}")
            print("Run manually: playwright install chromium")

setup(
    name="rfx-automation-backend",
    version="1.0.0",
    packages=find_packages(),
    install_requires=[
        line.strip() 
        for line in open('requirements.txt').readlines()
        if line.strip() and not line.startswith('#')
    ],
    cmdclass={
        'install': PostInstallCommand,
    }
)
```

**Paso 2:** Health check endpoint
```python
# backend/api/health.py (crear nuevo)
"""
Health check endpoints para verificar dependencias
"""
from flask import Blueprint, jsonify
import logging

health_bp = Blueprint('health', __name__, url_prefix='/api/health')
logger = logging.getLogger(__name__)

@health_bp.route('/', methods=['GET'])
def health_check():
    """Health check b√°sico"""
    return jsonify({
        "status": "healthy",
        "service": "RFX Automation Backend"
    })

@health_bp.route('/dependencies', methods=['GET'])
def check_dependencies():
    """Verificar todas las dependencias externas"""
    checks = {
        "database": _check_database(),
        "openai": _check_openai(),
        "cloudinary": _check_cloudinary(),
        "playwright": _check_playwright()
    }
    
    all_healthy = all(check["status"] == "ok" for check in checks.values())
    
    return jsonify({
        "status": "healthy" if all_healthy else "degraded",
        "checks": checks
    }), 200 if all_healthy else 503

def _check_playwright():
    """Verificar si Playwright est√° instalado"""
    try:
        from playwright.sync_api import sync_playwright
        
        with sync_playwright() as p:
            # Intentar lanzar browser
            browser = p.chromium.launch(headless=True)
            browser.close()
        
        return {
            "status": "ok",
            "message": "Playwright chromium available"
        }
    except Exception as e:
        return {
            "status": "error",
            "message": f"Playwright not available: {str(e)}",
            "action": "Run: playwright install chromium"
        }

def _check_database():
    """Verificar conexi√≥n a base de datos"""
    try:
        from backend.core.database import get_database_client
        db = get_database_client()
        # Test query
        db.client.table("users").select("id").limit(1).execute()
        return {"status": "ok", "message": "Database connected"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

def _check_openai():
    """Verificar API key de OpenAI"""
    try:
        from backend.core.config import get_openai_config
        config = get_openai_config()
        if not config.api_key:
            raise ValueError("API key not configured")
        return {"status": "ok", "message": "OpenAI configured"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

def _check_cloudinary():
    """Verificar configuraci√≥n de Cloudinary"""
    try:
        import cloudinary
        if not cloudinary.config().cloud_name:
            raise ValueError("Cloudinary not configured")
        return {"status": "ok", "message": "Cloudinary configured"}
    except Exception as e:
        return {"status": "error", "message": str(e)}
```

**Paso 3:** Registrar blueprint
```python
# backend/app.py
from backend.api.health import health_bp

def create_app(config_name='development'):
    app = Flask(__name__)
    
    # ... configuraci√≥n existente ...
    
    # Health check endpoints
    app.register_blueprint(health_bp)
    
    return app
```

**Paso 4:** Documentar en README
```markdown
# README.md

## üöÄ Instalaci√≥n

### Opci√≥n 1: Instalaci√≥n autom√°tica (recomendado)
```bash
pip install -e .
```
Esto instalar√° todas las dependencias incluyendo Playwright browsers.

### Opci√≥n 2: Instalaci√≥n manual
```bash
pip install -r requirements.txt
playwright install chromium
```

## üè• Health Check

Verificar que todas las dependencias est√©n instaladas:
```bash
curl http://localhost:5001/api/health/dependencies
```

Respuesta esperada:
```json
{
  "status": "healthy",
  "checks": {
    "database": {"status": "ok"},
    "openai": {"status": "ok"},
    "cloudinary": {"status": "ok"},
    "playwright": {"status": "ok"}
  }
}
```
```

**Archivos a crear/modificar:**
1. Crear `setup.py` (nuevo)
2. Crear `backend/api/health.py` (nuevo)
3. Modificar `backend/app.py` - Registrar health blueprint
4. Actualizar `README.md` - Documentar instalaci√≥n

**Tiempo estimado:** 4-5 horas

---

### 2.2 CENTRALIZAR FEATURE FLAGS

#### üìç Problema
**Ubicaci√≥n:** Dispersos en m√∫ltiples archivos

**Descripci√≥n:**
```python
# ‚ùå PROBLEMA: Flags dispersos
USE_AI_AGENTS = os.getenv('USE_AI_AGENTS', 'true')      # config.py
USE_OCR = os.getenv("RFX_USE_OCR", "true")              # rfx_processor.py
USE_ZIP = os.getenv("RFX_USE_ZIP", "true")              # rfx_processor.py
ENABLE_EVALS = os.getenv('ENABLE_EVALS', 'false')       # config.py
```

**Impacto:**
- Dif√≠cil saber qu√© features est√°n activas
- No hay documentaci√≥n centralizada
- Inconsistencia en valores por defecto

#### üîß Soluci√≥n Propuesta

**Paso 1:** Crear m√≥dulo de feature flags
```python
# backend/core/feature_flags.py (nuevo)
"""
Feature Flags centralizados del proyecto

Todos los feature flags deben definirse aqu√≠ para:
1. Documentaci√≥n centralizada
2. Valores por defecto consistentes
3. F√°cil auditor√≠a de features activas
"""
import os
from typing import Final
from dataclasses import dataclass

def _str_to_bool(value: str) -> bool:
    """Convertir string a boolean"""
    return value.lower() in ('true', '1', 'yes', 'on')

@dataclass
class FeatureFlags:
    """Feature flags del proyecto"""
    
    # ==================== AI Features ====================
    AI_AGENTS_ENABLED: Final[bool] = _str_to_bool(
        os.getenv('USE_AI_AGENTS', 'true')
    )
    """Usar sistema de 3 agentes AI para generaci√≥n de propuestas"""
    
    OCR_ENABLED: Final[bool] = _str_to_bool(
        os.getenv('RFX_USE_OCR', 'true')
    )
    """Usar OCR para extracci√≥n de texto de im√°genes"""
    
    # ==================== File Processing ====================
    ZIP_PROCESSING_ENABLED: Final[bool] = _str_to_bool(
        os.getenv('RFX_USE_ZIP', 'true')
    )
    """Permitir procesamiento de archivos ZIP"""
    
    # ==================== Evaluation & Testing ====================
    EVALS_ENABLED: Final[bool] = _str_to_bool(
        os.getenv('ENABLE_EVALS', 'false')
    )
    """Habilitar sistema de evaluaciones autom√°ticas"""
    
    # ==================== Chat Features ====================
    CHAT_FILE_ATTACHMENTS: Final[bool] = _str_to_bool(
        os.getenv('CHAT_ENABLE_ATTACHMENTS', 'true')
    )
    """Permitir adjuntar archivos en chat"""
    
    CHAT_DUPLICATE_DETECTION: Final[bool] = _str_to_bool(
        os.getenv('CHAT_DUPLICATE_DETECTION', 'true')
    )
    """Detectar productos duplicados en chat"""
    
    # ==================== Pricing Features ====================
    AUTO_PRICING_ENABLED: Final[bool] = _str_to_bool(
        os.getenv('ENABLE_AUTO_PRICING', 'true')
    )
    """Calcular precios autom√°ticamente desde cat√°logo"""
    
    # ==================== Debug & Development ====================
    DEBUG_MODE: Final[bool] = _str_to_bool(
        os.getenv('DEBUG_MODE', 'false')
    )
    """Modo debug con logs extendidos"""
    
    VERBOSE_LOGGING: Final[bool] = _str_to_bool(
        os.getenv('VERBOSE_LOGGING', 'false')
    )
    """Logging verbose para debugging"""
    
    @classmethod
    def get_all_flags(cls) -> dict:
        """Obtener todos los flags y sus valores"""
        return {
            name: getattr(cls, name)
            for name in dir(cls)
            if not name.startswith('_') and name.isupper()
        }
    
    @classmethod
    def print_active_flags(cls):
        """Imprimir flags activos (√∫til para debugging)"""
        print("\nüö© Feature Flags Activos:")
        for name, value in cls.get_all_flags().items():
            status = "‚úÖ ON" if value else "‚ùå OFF"
            print(f"  {status} {name}")
        print()

# Instancia global
feature_flags = FeatureFlags()
```

**Paso 2:** Endpoint para consultar flags
```python
# backend/api/health.py (agregar)
from backend.core.feature_flags import feature_flags

@health_bp.route('/feature-flags', methods=['GET'])
def get_feature_flags():
    """Obtener feature flags activos"""
    return jsonify({
        "flags": feature_flags.get_all_flags()
    })
```

**Paso 3:** Actualizar uso en servicios
```python
# ‚ùå ANTES
USE_AI_AGENTS = os.getenv('USE_AI_AGENTS', 'true') == 'true'

# ‚úÖ DESPU√âS
from backend.core.feature_flags import feature_flags

if feature_flags.AI_AGENTS_ENABLED:
    # Usar sistema de agentes
    pass
```

**Archivos a crear/modificar:**
1. Crear `backend/core/feature_flags.py` (nuevo)
2. `backend/api/health.py` - Agregar endpoint
3. `backend/core/config.py` - Remover flags duplicados
4. `backend/services/rfx_processor.py` - Usar flags centralizados
5. `backend/services/proposal_generator.py` - Usar flags centralizados

**Tiempo estimado:** 3-4 horas

---

### 2.3 RESOLVER TODOs/FIXMEs

#### üìç Problema
**Ubicaci√≥n:** 118 comentarios en 46 archivos

**Descripci√≥n:**
```python
# Ejemplos encontrados:
# TODO: Implement proper validation
# FIXME: This is a temporary hack
# XXX: This needs refactoring
# HACK: Workaround for Supabase limitation
```

**Impacto:**
- C√≥digo con soluciones temporales en producci√≥n
- T√©cnica debt acumulada

#### üîß Soluci√≥n Propuesta

**Paso 1:** Auditar y categorizar
```bash
# Script para extraer todos los TODOs
grep -rn "TODO\|FIXME\|HACK\|XXX" backend/ > todos_audit.txt
```

**Paso 2:** Clasificar por prioridad
```markdown
# todos_audit.md

## üî¥ CR√çTICOS (Resolver en Fase 2)
- [ ] `backend/services/function_calling_extractor.py:45` - TODO: Implement retry logic
- [ ] `backend/api/rfx.py:120` - FIXME: Validate user_id properly
- [ ] `backend/services/cloudinary_service.py:78` - HACK: Workaround for timeout

## üü° IMPORTANTES (Resolver en Fase 3)
- [ ] `backend/services/proposal_generator.py:200` - TODO: Add caching
- [ ] `backend/api/pricing.py:150` - FIXME: Optimize query

## üü¢ MEJORAS (Backlog)
- [ ] `backend/utils/text_utils.py:30` - TODO: Add more test cases
```

**Paso 3:** Convertir en GitHub Issues
```bash
# Script para crear issues autom√°ticamente
python scripts/create_issues_from_todos.py
```

**Tiempo estimado:** 2-3 horas (auditor√≠a), resolver gradualmente

---

## üìÖ ROADMAP DE IMPLEMENTACI√ìN

### Semana 1-2: FASE 1 - Problemas Cr√≠ticos
- [ ] **D√≠a 1-2:** Unificar cliente de base de datos (6h)
- [ ] **D√≠a 3-4:** Consolidar configuraci√≥n OpenAI (8h)
- [ ] **D√≠a 5:** Eliminar servicios duplicados (4h)
- [ ] **D√≠a 6-7:** Implementar retry consistente (8h)
- [ ] **D√≠a 8-10:** Estandarizar manejo de errores (12h)

**Total Fase 1:** 38 horas (~2 semanas)

### Semana 3-4: FASE 2 - Problemas Moderados
- [ ] **D√≠a 11-12:** Automatizar Playwright (5h)
- [ ] **D√≠a 13:** Centralizar feature flags (4h)
- [ ] **D√≠a 14-15:** Auditar y resolver TODOs cr√≠ticos (10h)

**Total Fase 2:** 19 horas (~1 semana)

### Semana 5+: FASE 3 - Mejoras Arquitect√≥nicas
- [ ] Documentar arquitectura
- [ ] Agregar tests de integraci√≥n
- [ ] Optimizar performance
- [ ] Resolver TODOs restantes

---

## üéØ M√âTRICAS DE √âXITO

### Antes de Refactorizaci√≥n
- ‚ùå Tasa de fallo intermitente: ~20-30%
- ‚ùå Configuraciones duplicadas: 2 sistemas OpenAI
- ‚ùå Servicios duplicados: 4 archivos
- ‚ùå Retry logic: Inconsistente (3 patrones)
- ‚ùå Manejo de errores: Return None en 130 casos

### Despu√©s de Refactorizaci√≥n
- ‚úÖ Tasa de fallo: <5%
- ‚úÖ Configuraci√≥n √∫nica de OpenAI
- ‚úÖ Servicios √∫nicos y documentados
- ‚úÖ Retry consistente en todos los servicios
- ‚úÖ Excepciones tipadas, sin return None

---

## üö® RIESGOS Y MITIGACI√ìN

### Riesgo 1: Breaking Changes
**Mitigaci√≥n:**
- Deprecar gradualmente (no eliminar inmediatamente)
- Mantener compatibilidad por 1 mes
- Tests exhaustivos antes de deploy

### Riesgo 2: Tiempo de Implementaci√≥n
**Mitigaci√≥n:**
- Priorizar problemas cr√≠ticos primero
- Implementar en sprints peque√±os
- Validar cada cambio antes de continuar

### Riesgo 3: Impacto en Producci√≥n
**Mitigaci√≥n:**
- Deploy gradual (canary deployment)
- Rollback plan preparado
- Monitoreo intensivo post-deploy

---

## üìû PR√ìXIMOS PASOS

1. **Revisar este plan** con el equipo
2. **Priorizar** qu√© problemas resolver primero
3. **Crear branch** `refactor/consistency-fixes`
4. **Comenzar con Fase 1** - Problema 1.1

---

**Documento creado:** 3 de Febrero, 2026  
**√öltima actualizaci√≥n:** 3 de Febrero, 2026  
**Autor:** An√°lisis automatizado del proyecto
