"""
Catalog Search Service - SYNC VERSION
Versi√≥n sincr√≥nica para uso en RFX Processor (c√≥digo sync)

Arquitectura h√≠brida:
1. Exact match (BD) - 0 tokens, <10ms
2. Fuzzy match (pg_trgm) - 0 tokens, <50ms  
3. Semantic search (Redis embeddings) - 50 tokens, ~150ms
"""
import json
import logging
import numpy as np
from typing import Optional, Dict, Any, List
from openai import OpenAI  # Sync client

logger = logging.getLogger(__name__)


class CatalogSearchServiceSync:
    """
    Servicio de b√∫squeda de cat√°logo - VERSI√ìN SINCR√ìNICA
    Para uso en c√≥digo sync como RFX Processor
    """
    
    def __init__(self, db_client, redis_client, openai_client: OpenAI):
        """
        Args:
            db_client: Supabase client
            redis_client: Redis sync client (redis.Redis)
            openai_client: OpenAI sync client
        """
        self.db = db_client
        self.redis = redis_client
        self.openai = openai_client
        
        # Thresholds configurables
        self.fuzzy_threshold = 0.90
        self.semantic_threshold = 0.75
        
        logger.info("üõí CatalogSearchServiceSync initialized (SYNC version)")
    
    def search_product(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None,
        limit: int = 1
    ) -> Optional[Dict[str, Any]]:
        """
        B√∫squeda h√≠brida en cascada (SYNC)
        
        L√≥gica inteligente:
        - Si organization_id existe ‚Üí buscar en cat√°logo de organizaci√≥n
        - Si NO existe ‚Üí buscar en cat√°logo individual del user_id
        
        Args:
            query: Nombre del producto a buscar
            organization_id: ID de la organizaci√≥n (opcional)
            user_id: ID del usuario (fallback si no hay org)
            limit: N√∫mero de resultados (default 1)
        
        Returns:
            Dict con producto encontrado o None
        """
        
        if not query:
            logger.warning("‚ö†Ô∏è Query missing")
            return None
        
        if not organization_id and not user_id:
            logger.warning("‚ö†Ô∏è Neither organization_id nor user_id provided")
            return None
        
        # L√≥gica inteligente: organizaci√≥n primero, user_id como fallback
        owner_type = "org" if organization_id else "user"
        owner_id = organization_id or user_id
        logger.info(f"üîç Searching: '{query}' ({owner_type}: {owner_id})")
        
        # 1. EXACT MATCH (m√°s r√°pido, gratis)
        exact_match = self._exact_match(query, organization_id, user_id)
        if exact_match:
            logger.info(f"‚úÖ EXACT match: {exact_match['product_name']}")
            return exact_match
        
        # 2. FUZZY MATCH (r√°pido, gratis, typos)
        fuzzy_match = self._fuzzy_match(query, organization_id, user_id)
        if fuzzy_match:
            logger.info(f"‚úÖ FUZZY match: {fuzzy_match['product_name']} (score: {fuzzy_match['confidence']:.2f})")
            return fuzzy_match
        
        # 3. SEMANTIC SEARCH (lento, cuesta tokens, sin√≥nimos)
        semantic_match = self._semantic_search(query, organization_id, user_id)
        if semantic_match:
            logger.info(f"‚úÖ SEMANTIC match: {semantic_match['product_name']} (score: {semantic_match['confidence']:.2f})")
            return semantic_match
        
        logger.info(f"‚ùå No match found for: '{query}'")
        return None
    
    def search_product_variants(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None,
        max_variants: int = 5
    ) -> List[Dict[str, Any]]:
        """
        B√∫squeda de m√∫ltiples variantes de un producto
        
        √ötil cuando hay m√∫ltiples opciones (ej: "Teque√±os" puede ser "Teque√±os Salados", "Teque√±os de Queso", etc.)
        
        Args:
            query: Nombre del producto a buscar
            organization_id: ID de la organizaci√≥n (opcional)
            user_id: ID del usuario (fallback si no hay org)
            max_variants: N√∫mero m√°ximo de variantes a retornar (default 5)
        
        Returns:
            Lista de productos encontrados, ordenados por confidence (mayor a menor)
        """
        
        if not query:
            logger.warning("‚ö†Ô∏è Query missing")
            return []
        
        if not organization_id and not user_id:
            logger.warning("‚ö†Ô∏è Neither organization_id nor user_id provided")
            return []
        
        owner_type = "org" if organization_id else "user"
        owner_id = organization_id or user_id
        logger.info(f"üîç Searching variants: '{query}' ({owner_type}: {owner_id})")
        
        all_matches = []
        
        # 1. EXACT MATCH
        exact_match = self._exact_match(query, organization_id, user_id)
        if exact_match:
            all_matches.append(exact_match)
            logger.info(f"‚úÖ EXACT match: {exact_match['product_name']}")
        
        # 2. FUZZY MATCH (m√∫ltiples resultados)
        fuzzy_matches = self._fuzzy_match_multiple(query, organization_id, user_id, limit=max_variants)
        for match in fuzzy_matches:
            # Evitar duplicados
            if not any(m['id'] == match['id'] for m in all_matches):
                all_matches.append(match)
        
        # 3. SEMANTIC SEARCH (si no hay suficientes matches)
        if len(all_matches) < max_variants:
            semantic_matches = self._semantic_search_multiple(query, organization_id, user_id, limit=max_variants)
            for match in semantic_matches:
                if not any(m['id'] == match['id'] for m in all_matches):
                    all_matches.append(match)
        
        # Ordenar por confidence (mayor a menor)
        all_matches.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        
        # Limitar a max_variants
        result = all_matches[:max_variants]
        
        if result:
            logger.info(f"‚úÖ Found {len(result)} variants for '{query}'")
            for i, match in enumerate(result, 1):
                logger.info(f"   {i}. {match['product_name']} (confidence: {match['confidence']:.2f})")
        else:
            logger.info(f"‚ùå No variants found for: '{query}'")
        
        return result
    
    def _exact_match(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None
    ) -> Optional[Dict[str, Any]]:
        """
        B√∫squeda exact match case-insensitive
        L√≥gica: organization_id primero, user_id como fallback
        
        Performance: <10ms, 0 tokens
        Accuracy: 100%
        """
        
        try:
            query_builder = self.db.client.table("product_catalog")\
                .select("id, product_name, product_code, unit_cost, unit_price, unit")
            
            # Filtrar por organization_id O user_id
            if organization_id:
                query_builder = query_builder.eq("organization_id", organization_id)
            else:
                query_builder = query_builder.eq("user_id", user_id).is_("organization_id", "null")
            
            response = query_builder\
                .eq("is_active", True)\
                .ilike("product_name", query)\
                .limit(1)\
                .execute()
            
            if response.data:
                product = response.data[0]
                return {
                    **product,
                    'match_type': 'exact',
                    'confidence': 1.0
                }
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Exact match error: {e}")
            return None
    
    def _fuzzy_match(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None
    ) -> Optional[Dict[str, Any]]:
        """
        B√∫squeda fuzzy con pg_trgm
        L√≥gica: organization_id primero, user_id como fallback
        
        Performance: ~50ms, 0 tokens
        Accuracy: ~85%
        """
        
        try:
            # Tokenizar query para b√∫squeda m√°s flexible
            words = query.lower().split()
            if not words:
                return None
            
            # Construir query con OR para cada palabra
            query_builder = self.db.client.table("product_catalog")\
                .select("id, product_name, product_code, unit_cost, unit_price, unit")
            
            # Filtrar por organization_id O user_id
            if organization_id:
                query_builder = query_builder.eq("organization_id", organization_id)
            else:
                query_builder = query_builder.eq("user_id", user_id).is_("organization_id", "null")
            
            response = query_builder\
                .eq("is_active", True)\
                .ilike("product_name", f"%{words[0]}%")\
                .limit(10)\
                .execute()
            
            if not response.data:
                return None
            
            # Calcular similitud simple (ratio de palabras coincidentes)
            best_match = None
            best_score = 0
            
            for product in response.data:
                product_name = product['product_name'].lower()
                
                # Contar palabras coincidentes
                matches = sum(1 for word in words if word in product_name)
                score = matches / len(words)
                
                if score > best_score and score >= (self.fuzzy_threshold - 0.2):  # M√°s flexible
                    best_score = score
                    best_match = product
            
            if best_match and best_score >= 0.7:  # Threshold m√≠nimo
                return {
                    **best_match,
                    'match_type': 'fuzzy',
                    'confidence': best_score
                }
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Fuzzy match error: {e}")
            return None
    
    def _fuzzy_match_multiple(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        B√∫squeda fuzzy que retorna m√∫ltiples matches
        √ötil para encontrar variantes de un producto
        """
        
        try:
            words = query.lower().split()
            if not words:
                return []
            
            # Construir query
            query_builder = self.db.client.table("product_catalog")\
                .select("id, product_name, product_code, unit_cost, unit_price, unit")
            
            # Filtrar por organization_id O user_id
            if organization_id:
                query_builder = query_builder.eq("organization_id", organization_id)
            else:
                query_builder = query_builder.eq("user_id", user_id).is_("organization_id", "null")
            
            response = query_builder\
                .eq("is_active", True)\
                .ilike("product_name", f"%{words[0]}%")\
                .limit(limit * 2)\
                .execute()
            
            if not response.data:
                return []
            
            # Calcular score para todos los productos
            matches = []
            for product in response.data:
                product_name = product['product_name'].lower()
                
                # Contar palabras coincidentes
                word_matches = sum(1 for word in words if word in product_name)
                score = word_matches / len(words)
                
                if score >= 0.5:  # Threshold m√≠nimo m√°s bajo para variantes
                    matches.append({
                        **product,
                        'match_type': 'fuzzy',
                        'confidence': score
                    })
            
            # Ordenar por score y limitar
            matches.sort(key=lambda x: x['confidence'], reverse=True)
            return matches[:limit]
            
        except Exception as e:
            logger.error(f"‚ùå Fuzzy match multiple error: {e}")
            return []
    
    def _semantic_search(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None
    ) -> Optional[Dict[str, Any]]:
        """
        B√∫squeda sem√°ntica con embeddings (SYNC)
        L√≥gica: organization_id primero, user_id como fallback
        
        Performance: ~150ms, ~50 tokens
        Accuracy: ~95%
        """
        
        try:
            # 1. Obtener embeddings cacheados de Redis
            owner_id = organization_id or user_id
            owner_type = "org" if organization_id else "user"
            cache_key = f"catalog_embeddings:{owner_type}:{owner_id}"
            cached = self.redis.get(cache_key)  # Sync call
            
            if not cached:
                logger.warning("‚ö†Ô∏è No cached embeddings - semantic search unavailable")
                return None
            
            catalog = json.loads(cached)
            products = catalog.get('products', {})
            
            if not products:
                logger.warning("‚ö†Ô∏è Empty catalog cache")
                return None
            
            # 2. Generar embedding del query (SYNC)
            query_embedding_response = self.openai.embeddings.create(
                model="text-embedding-3-small",
                input=query,
                encoding_format="float"
            )
            
            query_embedding = np.array(query_embedding_response.data[0].embedding)
            
            # 3. Calcular similitud con todos los productos
            best_match = None
            best_similarity = 0
            
            for product_id, product_data in products.items():
                product_embedding = np.array(product_data['embedding'])
                
                # Similitud coseno
                similarity = self._cosine_similarity(query_embedding, product_embedding)
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = {
                        'id': product_id,
                        'product_name': product_data['name'],
                        'unit_cost': product_data.get('cost'),
                        'unit_price': product_data.get('price'),
                        'match_type': 'semantic',
                        'confidence': float(similarity)
                    }
            
            # 4. Retornar si supera threshold
            if best_match and best_similarity >= self.semantic_threshold:
                return best_match
            
            return None
            
        except Exception as e:
            # Redis es opcional - el sistema funciona sin √©l usando EXACT + FUZZY
            error_msg = str(e)
            if "Connection refused" in error_msg or "redis" in error_msg.lower():
                logger.info(f"‚ÑπÔ∏è Semantic search unavailable (Redis not running) - using EXACT + FUZZY only")
            else:
                logger.warning(f"‚ö†Ô∏è Semantic search error: {e}")
            return None
    
    def _semantic_search_multiple(
        self, 
        query: str, 
        organization_id: str = None,
        user_id: str = None,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        B√∫squeda sem√°ntica que retorna m√∫ltiples matches
        √ötil para encontrar variantes sem√°nticamente similares
        """
        
        try:
            # 1. Obtener embeddings cacheados de Redis
            owner_id = organization_id or user_id
            owner_type = "org" if organization_id else "user"
            cache_key = f"catalog_embeddings:{owner_type}:{owner_id}"
            cached = self.redis.get(cache_key)
            
            if not cached:
                logger.warning("‚ö†Ô∏è No cached embeddings - semantic search unavailable")
                return []
            
            catalog = json.loads(cached)
            products = catalog.get('products', {})
            
            if not products:
                logger.warning("‚ö†Ô∏è Empty catalog cache")
                return []
            
            # 2. Generar embedding del query
            query_embedding_response = self.openai.embeddings.create(
                model="text-embedding-3-small",
                input=query,
                encoding_format="float"
            )
            
            query_embedding = np.array(query_embedding_response.data[0].embedding)
            
            # 3. Calcular similitud con todos los productos
            matches = []
            
            for product_id, product_data in products.items():
                product_embedding = np.array(product_data['embedding'])
                
                # Similitud coseno
                similarity = self._cosine_similarity(query_embedding, product_embedding)
                
                # Threshold m√°s bajo para variantes (0.65 vs 0.75)
                if similarity >= 0.65:
                    matches.append({
                        'id': product_id,
                        'product_name': product_data['name'],
                        'unit_cost': product_data.get('cost'),
                        'unit_price': product_data.get('price'),
                        'match_type': 'semantic',
                        'confidence': float(similarity)
                    })
            
            # 4. Ordenar por similitud y limitar
            matches.sort(key=lambda x: x['confidence'], reverse=True)
            return matches[:limit]
            
        except Exception as e:
            # Redis es opcional - el sistema funciona sin √©l usando EXACT + FUZZY
            error_msg = str(e)
            if "Connection refused" in error_msg or "redis" in error_msg.lower():
                logger.info(f"‚ÑπÔ∏è Semantic search unavailable (Redis not running) - using EXACT + FUZZY only")
            else:
                logger.warning(f"‚ö†Ô∏è Semantic search multiple error: {e}")
            return []
    
    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """
        Calcular similitud coseno entre dos vectores
        
        Returns:
            Float entre 0 y 1 (1 = id√©nticos)
        """
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return float(dot_product / (norm1 * norm2))
    
    def batch_search(
        self, 
        queries: List[str], 
        organization_id: str = None,
        user_id: str = None
    ) -> List[Optional[Dict[str, Any]]]:
        """
        B√∫squeda en batch de m√∫ltiples productos (SYNC)
        L√≥gica: organization_id primero, user_id como fallback
        
        Args:
            queries: Lista de nombres de productos
            organization_id: ID de la organizaci√≥n (opcional)
            user_id: ID del usuario (fallback)
        
        Returns:
            Lista de resultados (None si no match)
        """
        
        results = []
        
        for query in queries:
            result = self.search_product(query, organization_id, user_id)
            results.append(result)
        
        return results
    
    def get_catalog_stats(self, organization_id: str = None, user_id: str = None) -> Dict[str, Any]:
        """
        Obtener estad√≠sticas del cat√°logo (SYNC)
        L√≥gica: organization_id primero, user_id como fallback
        
        Returns:
            Dict con estad√≠sticas del cat√°logo
        """
        
        try:
            # Contar productos
            query_builder = self.db.client.table("product_catalog")\
                .select("id, unit_cost, unit_price", count="exact")
            
            # Filtrar por organization_id O user_id
            if organization_id:
                query_builder = query_builder.eq("organization_id", organization_id)
            else:
                query_builder = query_builder.eq("user_id", user_id).is_("organization_id", "null")
            
            response = query_builder\
                .eq("is_active", True)\
                .execute()
            
            total = response.count or 0
            
            # Calcular promedios
            products = response.data
            
            with_cost = sum(1 for p in products if p.get('unit_cost'))
            with_price = sum(1 for p in products if p.get('unit_price'))
            
            prices = [p['unit_price'] for p in products if p.get('unit_price')]
            avg_price = sum(prices) / len(prices) if prices else 0
            
            # Verificar cache de embeddings
            owner_id = organization_id or user_id
            owner_type = "org" if organization_id else "user"
            cache_key = f"catalog_embeddings:{owner_type}:{owner_id}"
            cache_exists = self.redis.exists(cache_key)  # Sync call
            
            return {
                'total_products': total,
                'products_with_cost': with_cost,
                'products_with_price': with_price,
                'avg_price': round(avg_price, 2),
                'cache_status': 'active' if cache_exists else 'inactive',
                'semantic_search_available': bool(cache_exists)
            }
            
        except Exception as e:
            # Redis es opcional, no es cr√≠tico
            logger.info(f"‚ÑπÔ∏è Stats calculated without Redis cache (optional): {e}")
            return {
                'total_products': 0,
                'products_with_cost': 0,
                'products_with_price': 0,
                'avg_price': 0,
                'cache_status': 'error',
                'semantic_search_available': False
            }
